# Processing

## Introduction

When you pass a string to **Fin** it will go through a number of _processors_:
1. At first it will be intercepted by any interceptors you define. Interceptors are just functions that take the input string to `Fin.run` and return another string which will be used for any further analysis.
2. Then it will be **lexed** (tokenized): it will be split into sentences and each sentence will be split further into tokens.
3. Then each token will be **POS tagged**: by annotating it with it's relevant part of speech annotation, like noun, verb ..etc.
4. Finally, each sentence will processed to resolve each the dependency tree.


## Example

The following chart explains each of the above steps with example:

[![Processing steps](../images/processing.png)](../images/processing.png)


## How the above information can be useful?

Imagine that you're mining data to have an idea about the most love/hated cars. The brands you're looking for are BMW, Lexus and Chevrolet. And the keywords that dictate the sentiment towards these cars are:

- Positive Sentiment:
	- love: 1
	- adore: 1
	- perfect: 1
	- amazing: 1
- Negative Sentiment:
	- broken: -1
	- hate: -1
	- waste: -1
	- old: -1

Now using the tokens, you can detect exactly where the above keywords are mentioned, and using the dependency tree you can see exactly what those keywords are describing. If a positive keyword describes a BMW then you add a point to the overall BMW score. If a negative keyword describes a BMW then you subtract one point from the overall BMW score.


So you can imagine after mining megabytes of data you'll have each car brand with a score.


The analysis of sentiment detection using the processors (dependency parsing and lexication) is called `detection` and the programmatic function that does this type of analysis is called a `detector`.

To know more about how to write and use detectors proceed to the next article.

## Real world annotations

In real world cases, annotating tokens with just `noun`, `verb`, `object`, `subject` might not suffice. The processors does a little bit more than just that.

Verbs can actually be `VBG` for the gerund form, `VBZ` for the third person form, `VBD` for the past form, `VBP` for the present form ... etc. While nouns can be `NN` for singular nouns, `NNS` for plural nouns, `NNP` for proper nouns ... etc.

For a complete list of annotations head to the specification articles.