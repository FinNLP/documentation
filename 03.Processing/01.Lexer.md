# Lexer

## What is lexing

Lexing is the process of separating a string of characters into different sections. The lexing library that **Fin** uses operates in two levels, first it tries to identify sentences and convert this string of text into an array of sentences, then on each sentence, it tries to identify tokens (words, punctuation ...etc) and convert a sentence into an array of token.

[![lexer steps](../images/lexer.png)](../images/lexer.png)

> __HINT__
> The lexer library is `~99%` compliant with the penn treebank corpus. Which makes it the best natural natural language processing lexer ever implemented in javascript.

## Example

```javascript

var input = "O'Relly Media (formerly O'Relly Associates), is a 49%-owned company. I didn't address any of the emails. Mr. T.J., an employee is at E!. He said: \"$4,000 was the profit.\" We met T.J. around 08:30 in the morning.";
// This is quite complex paragraph of text.
// We should learn a lot by running it through the lexer.

var processed = Fin.run(input);

```

Let's see the lexing processing result:

* `console.log(processed.sentences)`: logs an array of sentences
```javascript
[
	"O'Relly Media (formerly O'Relly Associates), is a 49%-owned company.",
	"I didn't address any of the emails.",
	"Mr. T.J., an employee is at E!.",
	"He said: \"$4,000 was the profit.\"",
	"We met T.J. around 08:30 in the morning."
]
```

* `console.log(processed.tokens)`: logs the token level lexication result
```javascript
[
	["O'Relly","Media","(","formerly","O'Relly","Associates",")",",","is","a","49%-owned","company","."],
	["I","did","n't","address","any","of","the","emails","."],
	["Mr.","T.J.",",","an","employee","is","at","E!","."],
	["He","said",":","\"","$4,000","was","the","profit",".","\""],
	["We","met","T.J.","around","08:30","in","the","morning","."]
]
```




## Lexing Details

### Separating sentences

The lexer identifies a sentence end by looking for punctuation marks that are usually found at the end of the sentence.

- **Full Stop**: `.`
- **Exclamation Mark**: `!`
- **Question Mark**: `?`
- **Ellipses**: `â€¦` or `...`

The above punctuation marks are considered separators between tokens.

> __NOTE__
> The lexer actually does more than that, by seeing for example if the full stop punctuation mark came after an abbreviation like: `Morty Jr. had fun last night with Mr. Barney`. and it also detects those sentences where the full stop mark is included inside the parenthesis or the quotation like: `I felt I'm "losing my mind." It was obvious.`

### Separating tokens

- Every two words that are separated by space are considered two different tokens.
- Every word that has a non-word character is considered to be consisting of multiple tokens, except for those cases:
	- Ratios and times: `1:4` `09:30`
	- Compound words: `Geo-location` `T.F.-based` `49%-owned`
	- Decade ranges: `1970's` `1970s`
	- Special punctuations that should be considered as one token: `...` `--`
	- Special cases with numbers: `45$` `45USD` `25nd` `'25`
	- English language contractions: `'d` `n't` `'s`
	- Common abbreviations: `Mr.` `Mrs.` `Jr.`
	- Acronyms: `U.S.` `U.K.`
	- Special cases with proper nouns: `E!` `O'Donnel` `4SQ'EM`

So based on the above rules you'll get an array of tokens.


## Extending the lexer

To extend the lexer please review the [repo's readme.md](https://github.com/FinNLP/lexed#extensibility).


## Standalone usage

The lexer library can also be used as a standalone package:

```bash
npm i --save lexed
```

For more about the lexer library (i.e. **lexed**), refer to it's [readme.md](https://github.com/FinNLP/lexed/blob/master/readme.md).
